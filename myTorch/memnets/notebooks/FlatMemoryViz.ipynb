{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "from myTorch.task.copying_memory import CopyingMemoryData\n",
    "from myTorch.memnets.load import load_experiment\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"/mnt/data/chinna/output/copying_memory_task/flatmemory_m64_k4_h80_linear/current\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_memory(save_dir, time_lag, seed):\n",
    "    experiment, model, data_iterator, device, config = load_experiment(save_dir)\n",
    "    config.time_lag = time_lag\n",
    "    config.batch_size = 1\n",
    "    config.seed = seed\n",
    "    new_data_iterator = CopyingMemoryData(seq_len=config.seq_len, time_lag=config.time_lag,\n",
    "                                          batch_size=config.batch_size, seed=config.seed)\n",
    "    data_iterator = new_data_iterator\n",
    "    \n",
    "    data = data_iterator.next()\n",
    "    seqloss = 0\n",
    "\n",
    "    model.reset_hidden(batch_size=1)\n",
    "\n",
    "    hiddens = []\n",
    "\n",
    "    for i in range(0, data[\"datalen\"]):\n",
    "\n",
    "        x = torch.from_numpy(np.asarray(data['x'][i])).to(device)\n",
    "        y = torch.from_numpy(np.asarray(data['y'][i])).to(device)\n",
    "        mask = float(data[\"mask\"][i])\n",
    "\n",
    "        model.optimizer.zero_grad()\n",
    "\n",
    "        output = model(x)\n",
    "        hiddens.append(model._h_prev[0][\"memory\"])\n",
    "        if config.task == \"copying_memory\":\n",
    "            loss = F.torch.nn.functional.cross_entropy(output, y.squeeze(1))\n",
    "        else:\n",
    "            loss = F.binary_cross_entropy_with_logits(output, y)\n",
    "\n",
    "        seqloss += (loss * mask)\n",
    "\n",
    "    seqloss /= sum(data[\"mask\"])\n",
    "    print(seqloss)\n",
    "\n",
    "    return hiddens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = example_memory(model, time_lag = 100, seed=11)\n",
    "\n",
    "x = len(memory)\n",
    "y = len(memory[0][0].detach().numpy())\n",
    "\n",
    "matrix = np.zeros((x,y))\n",
    "for i in range(0,x):\n",
    "    matrix[i] = memory[i][0].detach().numpy()\n",
    "plt.subplots(figsize=(20,15))\n",
    "ax = sns.heatmap(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_matrix = np.zeros((x,y))\n",
    "\n",
    "for i in range(0,x):\n",
    "    if i==0:\n",
    "        new_matrix[i] = matrix[i]\n",
    "    else:\n",
    "        new_matrix[i] = matrix[i] - matrix[i-1]\n",
    "plt.subplots(figsize=(20,15))\n",
    "ax = sns.heatmap(new_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
