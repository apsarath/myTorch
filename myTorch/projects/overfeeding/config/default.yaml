config_filename: "default.yaml"
description: "test_new_code"

project_name: "test_new_code"
ex_name: "testing_app_have_gem"


# model specific details

model:  "LSTM"
input_size: 8
output_size:  8
num_layers: 1
layer_size: [40]
activation: "tanh"

# optimization specific details

# Valid optimizer names: Adadelta, Adagrad, Adam, RMSprop, SGD
optim_name: "Adam"
lr: 1.0e-3
rho: 0.9
eps:  1.0e-8
weight_decay: 0.0
lr_decay: 0.0
beta_0: 0.9
beta_1: 0.999
alpha:  0.99
momentum: 0.0
centered: False
dampening:  0.0
nesterov: False
grad_clip:  [-10.0, 10.0]

max_steps: 10
rseed:  5
device: "cuda:1" # can be cpu or cuda or cuda:1, cuda:2

# task specific details
task: "copy"
num_bits: 8
seq_len: 5
batch_size: 10

# curriculum related details
min_seq_len: 5
max_seq_len: 15
step_seq_len: 3
average_over_last_n: 100
evaluate_over_n: 100
curriculum_seed: 6
new_lr: 0.001

# early stopping related details
# Now it is used to determine when the model should be grown.
#time_span: 10000

# Details related to expanding the rnn
#expanded_layer_size: [40]
#make_optimizer_wider: False
#expand_model_weights: True
#use_noise: True
#use_random_noise: True

# saving details
use_tflogger: True
save_every_n: 1000000000000
log_grad_norm: True

# GEM details
use_gem: True
memory_strength: 0.5
num_memories: 10